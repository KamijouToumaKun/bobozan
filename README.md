# Bobozan
solve bobozan game strategy with Nash equilibrium

## 波波攒游戏规则

### 初始版本

假设每回合有四类可选的动作：
* 聚气（energy）
* 攻击（attackx，其中x是指需要消耗的气数，气数越高的攻击越厉害）
* 防御（defence）
* 必杀技（防御也防不住。代码文件中，k=x，约定必杀技需要的气数）

### 之后还加入了
* 破防（breakthroughx，其中x是指需要消耗的气数），可以被防御住，但是之后对方不能再使用防御了

### 更复杂的规则变种1
* 变身：使用技能后，进入新的形态，每吸气一次等于别人五次
* 在二人对战中，这似乎不是一个经济的选择；除非是多人对战，这样做可以群攻、一次性多杀

### 更复杂的规则变种2

* 没有必杀技（可以认为k->inf）
* 有两个破防技能：breakthrough5和6
* breakthrough5会被attack1打败，类似于斗兽棋
* breakthrough6会被attack2打败
* 这可能很难解了，因为技能之间的严格优劣被破坏了，难以剔除劣策略

# 更新日志

## 版本0、solve.py 等

### 修改内容：当只有一个攻击类动作时，可以求解和验证

混合策略纳什均衡唯一。证明：https://www.zhihu.com/question/275344377/answer/380364234

solve.py 可以用方程组的方式收敛到混合策略纳什均衡，速度较快

print_equations.py 输出混合策略纳什均衡所满足的方程组

verify.py 给定不同state下的动作概率，代入方程组来验证是否真的收敛到了纳什均衡

k=3和4时的概率值来自：https://www.zhihu.com/question/275344377/answer/579353104 见回答和评论区

## 版本1、solve_multiple.py

### 修改内容：当有多个攻击类动作时，需要引入线性规划解法

此时不能再用 solve.py 联立方程组，因为得到的矩阵不满秩，对应多个解。而方程组又不方便限定变量的取值范围，给出的解可能很不合理。

solve_multiple.py 可以用线性规划的方式随机收敛到混合策略纳什均衡，速度较慢

类似于强化学习minimax-q算法，只是所有state以同样的频率访问到，并且更新

## 版本2、solve_multiple2.py

### 修改内容：加入破防类动作

在动作中加入了破防（breakthroughx，其中x是指需要消耗的气数），可以被防御住，但是之后对方不能再使用防御了

加上破防之后，概率部分收敛到的结果更不唯一了

例如必杀k=8，破防耗气为5，此时<6,0>也是必胜的，但获胜途径有多条

* 可以直接攻击破防，如果还没死的话就再攻击一次而胜利

* 也可以吸收变成<7,1>，然后再按照上述方案走：同样是必胜之势，只是对方可能多拖一轮

本文件算出来，吸气和破防的概率一般是五五开的，如：[0.53 0.   0.   0.   0.47 0.  ]

### 修改内容：可以选择剔除劣策略、简化局势

solve_multiple.py 有时候解出来的概率同是最优的，但是看起来是在“浪”

例如，当对方的气不够最低攻击限度时，己方不应该选择无谓的防御，即p(defence)应该为0，在 solve.py 中就是这么做的

这是一种剔除劣策略、简化局势的方法

而“浪”的选择中，可能会选择一两次无谓的防御，只是最后仍能获得胜利

例如 k=8, attack仅有5的情况，当双方的气不到5时，双方都应该努力攒气才对

* 而这次跑出来的结果，收敛得到的 p[2,0] 不是 [1,0,0] 

```
v:

[[0.5        0.14889064 0.66809442 0.71629508 0.99608092 0.30260185
  0.60176555 0.67553492 0.74460753]

[0.99601745 0.5        0.27491328 0.29201751 0.60540749 0.61425782
  0.83858238 0.04199693 0.45595999]

[0.99601746 0.99601745 0.5        0.2293886  0.92328923 0.97013374
  0.86650954 0.60234831 0.10405566]

[0.99999999 0.99601746 0.99601746 0.5        0.88580561 0.81109345
  0.90357999 0.02553662 0.67033609]

[0.99999999 0.99999999 0.99601746 0.99601746 0.5        0.79749676
  0.27923375 0.37053706 0.71568522]

[0.99999999 1.         1.         0.99601746 0.99608092 0.5
  0.22120403 0.53796232 0.13496775]

[0.99999999 1.         1.         1.         0.97311846 0.76120663
  0.5        0.01943865 0.66837701]

[1.         1.         1.         1.         1.         0.97116366
  0.88579747 0.5        0.29883698]

[1.         1.         1.         1.         1.         1.
  1.         1.         0.5       ]]

p:

-1,-1,-1,-1,-1,-1,-1,-1,-1,

[1. 0. 0.],-1,-1,-1,-1,-1,-1,-1,-1,

[0.55 0.   0.45],[1. 0. 0.],-1,-1,-1,-1,-1,-1,-1,

[1. 0. 0.],[0.55 0.   0.45],[1. 0. 0.],-1,-1,-1,-1,-1,-1,

[0.5 0.  0.5],[1. 0. 0.],[0.55 0.   0.45],[1. 0. 0.],-1,-1,-1,-1,-1,

[0.5 0.  0.5],[0.5 0.  0.5],[1. 0. 0.],[0. 0. 1.],[0.   0.99 0.01],-1,-1,-1,-1,

[0.5 0.  0.5],[0.5 0.  0.5],[0.5 0.  0.5],[1. 0. 0.],[0.93 0.07 0.  ],[0.24 0.34 0.42],-1,-1,-1,

-1,[0.5 0.  0.5],[0.5 0.  0.5],[0.5 0.  0.5],[1. 0. 0.],[0.03 0.72 0.25],[0.11 0.66 0.23],-1,-1,

-1,-1,-1,-1,-1,-1,-1,-1,-1,
```

* 又如这次跑出来的结果，收敛到不同的纳什均衡，且得到的 p[4,0] 不是 [1,0,0] 

```
[[0.5        0.99689932 0.10369555 0.81159096 0.19745167 0.92014893
  0.28813071 0.95220512 0.05310128]

[0.73249175 0.5        0.4964996  0.19587621 0.48185376 0.2981694
  0.61792651 0.95516981 0.58716766]

[0.92857766 0.73249175 0.5        0.33306888 0.4917762  0.78668369
  0.62257974 0.07920253 0.11467094]

[0.99999999 0.92857766 0.73249175 0.5        0.91422945 0.62882522
  0.8047908  0.27472521 0.77127297]

[1.         0.99999999 0.92857766 0.73249175 0.5        0.66250753
  0.49652694 0.25055156 0.73918025]

[1.         1.         0.99999999 0.92857766 0.73249175 0.5
  0.88618599 0.60260141 0.22623466]

[1.         1.         1.         1.         0.8849877  0.65624713
  0.5        0.58819187 0.69899801]

[1.         1.         1.         1.         1.         0.85217521
  0.74751596 0.5        0.52028988]

[1.         1.         1.         1.         1.         1.
  1.         1.         0.5       ]]

-1,-1,-1,-1,-1,-1,-1,-1,-1,

[1. 0. 0.],-1,-1,-1,-1,-1,-1,-1,-1,

[1. 0. 0.],[1. 0. 0.],-1,-1,-1,-1,-1,-1,-1,

[1. 0. 0.],[1. 0. 0.],[1. 0. 0.],-1,-1,-1,-1,-1,-1,

[0.5 0.  0.5],[1. 0. 0.],[1. 0. 0.],[1. 0. 0.],-1,-1,-1,-1,-1,

[0.5 0.  0.5],[0.63 0.   0.37],[1. 0. 0.],[0.62 0.38 0.  ],[0.78 0.22 0.  ],-1,-1,-1,-1,

[0.5 0.  0.5],[0.5 0.  0.5],[0.5 0.  0.5],[1. 0. 0.],[0.78 0.22 0.  ],[0.3  0.16 0.54],-1,-1,-1,

-1,[0.5 0.  0.5],[0.5 0.  0.5],[0.5 0.  0.5],[1. 0. 0.],[0.13 0.29 0.59],[0.16 0.33 0.5 ],-1,-1,

-1,-1,-1,-1,-1,-1,-1,-1,-1,
```

solve.py 中采用解方程的方法 则必须在当对方的气不够最低攻击限度时，己方剔除防御动作，才能保证求解的矩阵仍是方阵且满秩

线性规划方法本不用剔除，但是为了简化局势，solve_multiple2.py 提供了 flag_min_action_attack_energy_cost 这一选项，默认是关闭的

如果打开，则求解时加入人为限制，不考虑defence这一选项，p中直接少了这一维度

### 修改内容：修复BUG

solve_multiple.py 中的BUG：当动作中有耗气>1的时候，相比起原来 solve.py 求解的states，需要求解更多state

所以 solve_multiple.py 求解出来的v有很大随机性，这不代表收敛到不同的纳什均衡，而是其答案是错误的！

solve_multiple2.py 中修改了这一BUG，同时尝试了整个v矩阵初始化和求解，仅对下三角v初始化和求解，仅对原始的 solve.py 中那些states求解等三种方案

其中，方案1相对来说是最正确的

方案2中，因为此时状态转移不保证始终有state[0]>=state[1]，但是我们只对下三角的v进行初始化和求解，这样一来，当状态转移到上三角时，取到的v值仍是错的。

奇怪的是，虽然取到的v值仍是错的，但也能给出比较稳定的结果

在只有attack1的情况下，三者的结果是一样的

* 上述 k=8, attack仅有5的情况

```
v=
[[ 0.5        -1.         -1.         -1.         -1.         -1.
  -1.         -1.         -1.        ]
 [ 0.6279577   0.5        -1.         -1.         -1.         -1.
  -1.         -1.         -1.        ]
 [ 0.80835305  0.6279577   0.5        -1.         -1.         -1.
  -1.         -1.         -1.        ]
 [ 1.          0.80835305  0.6279577   0.5        -1.         -1.
  -1.         -1.         -1.        ]
 [ 1.          1.          0.80835305  0.6279577   0.5        -1.
  -1.         -1.         -1.        ]
 [ 1.          1.          1.          0.80835305  0.6279577   0.5
  -1.         -1.         -1.        ]
 [ 1.          1.          1.          1.          0.78804256  0.59137301
   0.5        -1.         -1.        ]
 [ 1.          1.          1.          1.          1.          0.76292818
   0.67868453  0.5        -1.        ]
 [ 1.          1.          1.          1.          1.          1.
   1.          1.          0.5       ]]

p=
-1,-1,-1,-1,-1,-1,-1,-1,-1,

[1. 0. 0.],-1,-1,-1,-1,-1,-1,-1,-1,

[1. 0. 0.],[1. 0. 0.],-1,-1,-1,-1,-1,-1,-1,

[1. 0. 0.],[1. 0. 0.],[1. 0. 0.],-1,-1,-1,-1,-1,-1,

[0.5 0.  0.5],[1. 0. 0.],[1. 0. 0.],[1. 0. 0.],-1,-1,-1,-1,-1,

[0.5 0.  0.5],[0.5 0.  0.5],[1. 0. 0.],[0.9 0.1 0. ],[0.91 0.09 0.  ],-1,-1,-1,-1,

[0.5 0.  0.5],[0.5 0.  0.5],[0.5 0.  0.5],[1. 0. 0.],[0.89 0.11 0.  ],[0.39 0.04 0.56],-1,-1,-1,

[0.5 0.  0.5],[0.5 0.  0.5],[0.5 0.  0.5],[0.5 0.  0.5],[1. 0. 0.],[0.23 0.03 0.74],[0.3  0.06 0.64],-1,-1,

-1,-1,-1,-1,-1,-1,-1,-1,-1,
```

## 版本3、solve_multiple3.py

### 修改内容：分阶段来解

由于破防不可逆，我们分阶段来解，这样循序渐进，思路清晰

基本思路是基于 solve_multiple2.py 的方案2的，只需要求解下三角，而上三角可以通过对称得到

* 先求解v（可以利用对称性，只求解下三角），再求解p（不能利用对称性，还需要求解上三角）

* 先解决双方破防的情况，其实不用解，易知无论动作如何，v矩阵的对角线为DRAW，下三角为WIN，上三角为LOSE

* 再解决次等的：我破防，对方未破防，但是我的气更多的情况。只需要解决下三角的情况，上三角部分不用解，易知是LOSE：对方不需要考虑防御，采用跟双方破防一样的战术即可。对角线使用纳什均衡可能有问题，在下一章节进行讨论

* 我未破防，对方破防的情况：不用求解，直接通过我破防，对方未破防的情况对称得到

* 最后解决最难的：双方未破防的情况

### 修改内容：修复BUG

```
for m in range(0, k): # m = 1,2,3,4,...,k-1 # TODO: 以前这里一直写错了! 
```

### 修改内容：进一步使用剔除劣战略法则，简化局势

首先，剔除的劣战略可以是弱劣战略，不只是严格劣战略

https://www.zhihu.com/question/66845475/answer/2155269488

弱劣战略是A战略的payoff小于等于B战略的payoff，严格劣战略是A战略的payoff小于B战略的payoff

以下为了方便叙述，假设只有低级和高级两个动作，这里高级是指当前的气能支持的最强的动作

#### 在双方未破防的情况下，似乎只有：当对方的气不够最低攻击限度时，己方剔除防御动作 这一劣战略

* 对方吸 我吸 <= 低级和高级
* 对方低 我吸 <= 低级 <= 高级
* 对方高 我吸 <= 低级 <= 高级
* 对方防 我吸 >= 低级（高级不一定，如果把对方也破防了呢）

可以看到，低级总是 <= 高级或者 < 吸

但是 不确定低级攻击是低于谁 二者居其一 且只居其一 所以低级攻击并不一直是谁的劣战略、不能剔除

事实上，解出来的结果反而是，只用低级攻击、破防攻击和必杀技，不要用高级而不破防的攻击：不经济

#### 在一方破防的情况下，则有更多的劣战略可以剔除

先假设是对方破防 己方有防

* 对方吸 我防御 <= 吸 <= 低级和高级攻击
* 对方低 我吸 <= 低级 <= 防御 <= 高级
* 对方高 我吸和低级 <= 高级和防（高级不一定小于防，因为对方可能也把我破防）

综上吸和低级总是 <= 高级和防御 有防方应该高级或者防 而不考虑低级

特别的，己方的气不够最低攻击限度时，高级攻击将退化成吸。不然，只有防御一个动作，则一直防御下去：这就不合理了

再把视角转过去 假设是己方破防 对方有防 对方只有两个动作

* 对方高 我吸 = 低级 <= 高级
* 对方防 我吸 >= 低级（高级不一定，如果把对方也破防了呢）

综上，低级总是 <= 吸，所以破防方应该采用吸或者高级 而不考虑低级

综上，在一方破防的情况下，双方都只有两个动作，大大简化了局势

### 现在考虑在一方破防的情况下，v矩阵的对角线：使用纳什均衡来解可能有问题！

对角线是一个难点，之前的程序解出来的收敛到的结果往往很不一致

根据对称性，我们只能知道，如果己方破防，则v对角线 <= 0.5：双方的气一样多，就算对方不用防御也至少能达到DRAW，而对方可以防御时己方一定落于下风

假设存在attack1

#### v<0,0>:

没有说的，双方选择吸气，变到v<1,1>的情况

#### v<1,1>: 破防方的角度

如果不考虑简化局势，而让对方也可以选择吸

```
	对方 吸 		高级		防御
我
吸	v<2,2>		0		v<2,1>
高级	1		v<0,0>		0 失败
```

方程形式: v<1,1> = pv<2,2>+(1-p) = (1-p)v<0,0> = pv<2,1>

pv<0,0> = 0 得出 p=0 或 v<0,0>=0

* 情况1. v<0,0> = 0

* 情况2. p=0: 则 v<1,1>=1 矛盾 这就是导入对方可以吸的意义 才能导出矛盾

0 = pv<2,2>+(1-p) = pv<2,1>

pv<2,2>+(1-p) >= 0 + 0 = 0 取等于 v<2,2>=0 且 p=1 也就是我一定吸

且 v<2,1> = 0: 也是0

类似地 可以推得整个对角线都是0即LOSE 我们人为将对角线设置为0即可

采取的策略是：己方一定吸，但是为什么要这样引颈受戮呢？？？

#### v'<1,1>: 未破防方的角度

对称一下, 算一下人家的情况
```
	对方 吸 		高级
我
吸	v'<2,2>		0	
高级	1		v'<0,0>
防御 	v'<1,2>		1
```

方程形式: v'<1,1> = pv'<2,2> + q + (1-p-q)v'<1,2> = qv'<0,0> + (1-p-q)

* 方法1. (v'<1,1>-1) (1-q) + p = 0

(1-v'<1,1>) (1-q) = p

解不出来

* 方法2. v'是v的对称 所以 1 = p+q+1-p-q = q+1-p-q

得到 p=0 意思是不能吸 这证明我们剔除劣策略是正确的

而 q 随便 因为高级 和 防御 所对应的结果是一样的 都是必胜

但是其实不是随便的! 这建立在破防方一定吸、摆烂的前提下 但是破防方未必摆烂

#### v<1,1>: 重新回到未破防方的角度

```
	对方 高级		防御
我
吸	0		v<2,1>
高级	v<0,0>		0 失败
```

方程形式: v<1,1> = pv<2,2>+(1-p) = (1-p)v<0,0> = pv<2,1>

代入：0 = (1-p) = pv<2,1>

解出来还是 p=1，v<2,1>=0，但还是无法解释引颈受戮的问题

而且，我们上述的人肉的推理用到了不等式放缩才能解出来

而如果直接代入线性规划和方程的方法都完全解不出来，因为 a矩阵完全是0矩阵了，求解完全没有意义

```
a_temp = np.ones((3,3))
a_temp[:-1, :-1] = -a[(1,0)][state]
a_temp[:, -1] = -1 # 对方各种动作的收益均等于v
a_temp[-1, :] = 1 # 所有动作的概率之和为1
a_temp[-1, -1] = 0
b = np.zeros((3, ))
b[-1] = 1

from scipy.linalg import solve
x = solve(a_temp, b)
p[(1,0)][state], new_v[(1,0)][state] = x[:-1], x[-1]
if abs(new_v[(1,0)][state] - v[(1,0)][state]) > delta:
	v[(1,0)][state] = new_v[(1,0)][state]
	return False # not convence
return True
```

#### 对角线: 直接列出双方的四种情况求解

v<1,1> 为例
```
	对方 吸p 		高级1-p
我

q<1	pq		(1-p)q
高级	1		<0,0>

1-q>0	p(1-q)		(1-p)(1-q)
防御	<1,2>		1
```
发现 对方只需要让1-q 趋近于 0 使得 p(1-q)趋近于0 于是唯一可能让己方占便宜的 <1,2> 也难以达到

但同时, 1-q不能完全等于0 即不能100%采用高级攻击的方法 否则破防方可以也用高级攻击 可以无限一直拖下去 事实上将会得到DRAW

可以理解为 未破防方 99%攻击 1%防御

破防方 只能也采用p趋于1的攻击 暂时抵御对方的攻击 但是对方一旦变招 虽然概率为一阶无穷小 也是赢 只是局面长度趋向于一阶无穷大

除非 刚好赶上 对方变招防御的时候 自己吸气 这样变成v<2,1> 就有转机了 但是概率是二阶无穷小 收益大小也有限 所以期望仍然是0

整个对角线都是这样的逻辑, get了

所以说，纳什均衡解出来的v的结果还真是对的，但是存在问题

方程形式: v<1,1> = p0 + (1-p)v<0,0> = pv<2,1>

而 v<0,0> 又等于 v<1,1>

代入 v<1,1>=0.00134971, p=0, 1-p=1, v<2,1>=0.18193591

0.00134971 = 0.99*0.00134971 = 0.01*0.18193591

只是在delta范围内, 其实本质是对角线=0

这一误差会导致收敛很慢 以及对于其他非对角线v造成误差的累计

对角线的p不能靠纳什均衡来解 而要人为给出

#### 非对角线的情况

例如 上述 v<1,1> 的纳什均衡方程 0 = pv<2,2>+(1-p) = pv<2,1> 中 p=0

于是整个方程纳什均衡方程就不成立了，需要靠线性规划形式

v<1,1> <= pv<2,2>+(1-p)

v<1,1> <= pv<2,1>

代入 v<1,1>=0, p=1

0 <= v<2,2>

0 <= v<2,1>

其中上面的式子取等，v<2,2> = 0，使得线性规划成立

但是 v<2,1> 也不一定等于0了，事实上，程序解出来非对角线的部分也不等于0

如v<1,0>:
```
	对方 吸 		防御
我
吸	v<2,1>		v<2,0>
高级	1		v<0,0>=0
```

方程形式: v<1,0> = pv<2,1>+(1-p) = pv<2,0>

程序解出来 结果约是0.31381651 = 0.84*0.18181818 + 0.16 = 0.84*0.37418412

符合结果 也就是说非对角线是可以靠程序来解决的!

我们尝试 k=8, attions = {attack1, attack2, attack3, breakthrough5} 的情况

* solve_multiple2.py 中，方案1的结果的确是最接近正确的，因为其与本方案的结果，在双方的气 <= 4（不涉及破防）时是一致的，策略上也只采用最经济的attack1而不考虑attack2和3。而在双方未破防 <5,0> 的情况下 答案也接近是1即WIN 必胜之势

* 只是其 v<5,0> 还不是完全等于1 因为delta部分允许误差 然后使得 <5,1> 等v值也连带着累计了误差 不够完美

* 而 solve_multiple2.py 方案2和方案3 的解是不对的

## TODO：最终版本：强化学习解法

我真的尝试写了强化学习minimax-q，但结果却很不稳定

* 可能是因为所有state并不是以同样的频率访问到？

* 而且，如上面所分析到的，minimax-q在很多特殊情况可能会出问题，无法求解？
