# Bobozan
solve bobozan game strategy with Nash equilibrium

## 波波攒游戏规则
假设每回合有四类可选的动作：
* 聚气（energy）
* 攻击（attackx，其中x是指需要消耗的气数，气数越高的攻击越厉害）
* 防御（defence）
* 必杀技（防御也防不住。代码文件中，k=x，约定必杀技需要的气数）

## 当只有一个攻击类动作时

### 当该动作耗气为1时，只有唯一的混合策略纳什均衡

证明：https://www.zhihu.com/question/275344377/answer/380364234

### 当该动作耗气大于1时，可能有多个混合策略纳什均衡

solve.py 可以用方程组的方式收敛到混合策略纳什均衡，速度较快

print_equations.py 输出混合策略纳什均衡所满足的方程组

verify.py 给定不同state下的动作概率，代入方程组来验证是否真的收敛到了纳什均衡

k=3和4时的概率值来自：https://www.zhihu.com/question/275344377/answer/579353104 见回答和评论区

## 当有多个攻击类动作时

### 容易想到，存在多个纳什均衡：

例如同时存在attack1和attack2

我们令attack1之外的动作概率都是0，相当于没有其他的动作，此时用solve.py联立方程组能解出一个纳什均衡

我们令attack2之外的动作概率都是0，相当于没有其他的动作，此时用solve.py联立方程组也能解出一个（其实是多个）纳什均衡

我们对各attack动作做混合的假设，也能解出一个纳什均衡

### 线性规划解法

此时不能再用 solve.py 联立方程组，因为得到的矩阵不满秩，对应多个解。而方程组又不方便限定变量的取值范围，给出的解可能很不合理。

solve_multiple.py 可以用线性规划的方式随机收敛到某一个混合策略纳什均衡，速度较慢

类似于强化学习minimax-q算法，只是所有state以同样的频率访问到，并且更新

用它来解仅一个攻击动作且耗气大于1的情况，有时候给出的解不合理

### 强化学习解法：TODO

我真的尝试写了强化学习minimax-q，但结果却很不稳定。可能是因为所有state并不是以同样的频率访问到？
